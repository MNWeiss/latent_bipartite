---
title: "Ising Model of Group-by-individual Data"
output:
  word_document: default
  html_document:
    df_print: paged
---

# Define Ising model functions

```{r}
library(Rcpp)

# Fit Ising model given number of individuals (N) and GBI matrix (X).
fit_ising <- function(N, X) {
  # Convert data to be 1s and -1s.
  X_ <- X
  X_[X_ == 0] <- -1
  # Conditional distributions form system of logistic regressions (I think), use this to estimate coefficients.
  A <- matrix(0, N, N)
  M <- rep(0, N)
  for (i in 1:N) {
    coefficients <- glm(X[, i] ~ X_[, -i], family="binomial")$coefficients
    A[i, -i] <- coefficients[2:N]
    M[i] <- coefficients[1]
  }
  ising_model <- list(N=N, A=A, M=M, X=X, X_=X_)
  ising_model
}

# Samples observation data from fitted Ising model using MCMC.
sample_data_from_ising <- function(ising_model, num_iterations=10000, thin=1000, cpp=TRUE) {
  # Define likelihood function.
  loglk <- function(x) {
    target <- 0
    for (i in 1:N) {
      target <- target + sum(ising_model$M[i] * x[i])
      for (j in 1:N) {
        if (i < j) {
          target <- target + sum(0.5 * ising_model$A[i, j] * x[i] * x[j])
        }
      }
    }
    target
  }
  # MCMC where proposals are generated by flipping a single element from the previous sample.
  X_sim <- matrix(0, num_iterations, N)
  X_sim[1, ] <- sample(c(-1, 1), N, replace=TRUE)
  for (i in 2:num_iterations) {
    flip_idx <- sample(1:N, size=1)
    x_candidate <- X_sim[i - 1, ]
    x_candidate[flip_idx] <- -1 * x_candidate[flip_idx]
    # loglk_prev <- loglk(X_sim[i - 1, ])
    if (cpp) {
      loglk <- loglik_ising
    } else {
      loglk <- loglik_ising_nocpp
    }
    loglk_prev <- loglk(N, ising_model$M, ising_model$A, X_sim[i - 1, ])
    loglk_candidate <- loglk(N, ising_model$M, ising_model$A, x_candidate)
    alpha <- exp(loglk_candidate - loglk_prev)
    if (runif(1) < alpha) { # Accept
      X_sim[i, ] <- x_candidate
    } else { # Reject
      X_sim[i, ] <- X_sim[i - 1, ]
    }
  }
  # Convert back to 1s and 0s
  X_sim[X_sim == -1] <- 0
  # Apply thinning
  idxs <- sample(1:num_iterations, thin, replace=TRUE)
  X_sim <- X_sim[idxs, ]
  X_sim
}

sample_data_from_ising_bayes <- function(params, num_iterations=10000, thin=1000, cpp=TRUE) {
  # MCMC where proposals are generated by flipping a single element from the previous sample.
  X_sim <- matrix(0, num_iterations, N)
  X_sim[1, ] <- sample(c(-1, 1), N, replace=TRUE)
  chain_idxs <- sample(1:dim(params$alpha)[1], size=num_iterations, replace=TRUE)
  for (i in 2:num_iterations) {
    flip_idx <- sample(1:N, size=1) # Entry in the sample vector to flip.
    x_candidate <- X_sim[i - 1, ]
    x_candidate[flip_idx] <- -1 * x_candidate[flip_idx]
    if (cpp) {
      loglk <- loglik_ising
    } else {
      loglk <- loglik_ising_nocpp
    }
    loglk_prev <- loglk(N, params$alpha[chain_idxs[i], ], params$beta[chain_idxs[i], , ], X_sim[i - 1, ])
    loglk_candidate <- loglk(N, params$alpha[chain_idxs[i], ], params$beta[chain_idxs[i], , ], x_candidate)
    alpha <- exp(loglk_candidate - loglk_prev)
    if (runif(1) < alpha) { # Accept
      X_sim[i, ] <- x_candidate
    } else { # Reject
      X_sim[i, ] <- X_sim[i - 1, ]
    }
  }
  # Convert back to 1s and 0s
  X_sim[X_sim == -1] <- 0
  # Apply thinning
  idxs <- sample(1:num_iterations, thin, replace=TRUE)
  X_sim <- X_sim[idxs, ]
  X_sim
}

cppFunction('double loglik_ising(int N, NumericVector M, NumericMatrix A, NumericVector x) {
    double target = 0.0;
    for (int i = 0; i < N; i++) {
      target += M[i] * x[i];
      for (int j = 0; j < N; j++) {
        if (i < j) {
          target += 0.5 * A(i, j) * x[i] * x[j];
        }
      }
    }
    return(target);
}')

loglik_ising_nocpp <- function(N, M, A, x) {
  target <- 0
  for (i in 1:N) {
    target <- target + M[i] * x[i]
    for (j in 1:N) {
      if (i < j) {
        # print(A[i, j] * x[i] * x[j])
        target <- target + 0.5 * A[i, j] * x[i] * x[j]
      }
    }
  }
  target
}
```

```{stan, output.var="logregsys"}
data {
  int<lower=0> N;
  int<lower=0> G;
  int<lower=-1, upper=1> X[N, G, N]; // X[i, , ] is design matrix (without intercept) for the regression where i is the response node. The i-th element of the design matrix is the intercept.
  int<lower=0, upper=1> Y[N, G]; // Y[, i] is the response vector for the regression where i is the response node.
}
parameters {
  // real beta[N, N]; // Interaction effects and intercepts. (i, i) is the intercept for the i-th regression.
  cholesky_factor_corr[N] beta_chol; // Cholesky decomposition of beta matrix.
  // vector<lower=0>[N] beta_scale; // Scale parameter for beta.
  vector[N] alpha;
}
transformed parameters {
  matrix[N, N] beta = diag_matrix(alpha - 1.0) + (beta_chol * beta_chol');
}
model {
  for (i in 1:N) {
    Y[i, ] ~ bernoulli_logit(to_matrix(X[i, , ]) * to_vector(beta[i, ]));
  }
  // beta_scale ~ cauchy(0, 2.5);
  alpha ~ normal(0, 2.5);
  beta_chol ~ lkj_corr_cholesky(2);
}
```

# Simulate data

Simulate the GBI data using the multivariate Bernoulli method.

```{r}
# Set main parameters
N <- 8 # Number of individuals
G <- 100 # Number of groups

# Draw mean prob. of being in group and covariance matrix using LL^T.
mu <- rnorm(N)
sigma_lower <- abs(rnorm(0.5 * N * (N + 1)))
L <- matrix(0, N, N)
L[upper.tri(L, diag=TRUE)] <- sigma_lower
sigma <- L %*% t(L)

# Draw latent variables from MVN and use logistic with Bernoulli to generate data.
z <- mvtnorm::rmvnorm(G, mu, sigma)
X <- matrix(rbinom(G * N, 1, plogis(z)), G, N)
head(X)
```

# Fit the model

Fit the model, simulate data, and compare to original.

```{r}
X <- as.matrix(read.csv("/home/jordan/Downloads/Hectors dolphin GBI.csv"))
N <- ncol(X)
G <- nrow(X)
colnames(X) <- NULL
head(X)
```

```{r}
# Fit Ising model.
fit <- fit_ising(N, X)

# Simulate data from fitted model.
system.time(X_sim <- sample_data_from_ising(fit, thin=1000, cpp=TRUE))
# system.time(X_sim <- sample_data_from_ising(fit, thin=G, cpp=FALSE))
head(X_sim)

# Calculate SRI from original and simulated data.
sri <- asnipe::get_network(X)
sri_sim <- asnipe::get_network(X_sim)

# Plot SRI from original data against the SRI from simulated data.
plot(sri[upper.tri(sri)], sri_sim[upper.tri(sri_sim)], xlab="True SRI", ylab="Ising SRI")
abline(a=0, b=1)
```

```{r}
plot(fit$A[upper.tri(fit$A)], sri[upper.tri(sri)], xlab="Ising Interaction Term", ylab="SRI")
```

```{r}
data <- list(
  N=N,
  G=G,
  X=array(0, dim=c(N, G, N)),
  Y=matrix(0, N, G)
)
for (i in 1:N) {
  data$X[i, , ] <- X
  data$X[i, , i] <- 1
  data$X[data$X == 0] <- -1
  data$Y[i, ] <- t(X[, i])
}

# fit_bayes <- sampling(logregsys, data, cores=4)
fit_bayes <- vb(logregsys, data)

fit_bayes
```

```{r}
chain <- extract(fit_bayes)
isri <- apply(chain$beta, c(2, 3), mean)
# summary(fit_bayes, par="beta")
sri <- asnipe::get_network(X)

params <- list(
  alpha=chain$alpha,
  beta=array(0, dim=c(nrow(chain$beta), N, N))
)
for (i in 1:N) {
  params$beta[, i, -i] <- chain$beta[, i, -i]
}

sim_bayes <- sample_data_from_ising_bayes(params, thin=G * 1000, cpp=TRUE)

sims <- array(0, c(1000, N, N))
for (i in 1:1000) {
  X_sim_bayes <- sim_bayes[sample(1:nrow(sim_bayes), G), ]
  
  # Calculate SRI from original and simulated data.
  sims[i, , ] <- asnipe::get_network(X_sim_bayes)
}
sims_q <- apply(sims, c(2, 3), function(x) quantile(x, probs=c(0.025, 0.5, 0.975)))

df <- data.frame(lower=sims_q[1, , ][upper.tri(sri)], middle=sims_q[2, , ][upper.tri(sri)], upper=sims_q[3, , ][upper.tri(sri)], sri=sri[upper.tri(sri)])
ggplot(df, aes(x=sri, y=middle)) +
  geom_point() +
  geom_errorbar(aes(ymin=lower, ymax=upper)) +
  geom_abline(slope=1) +
  labs(x="SRI", y="Simulated SRI (from Ising)")

plot(sri[upper.tri(sri)], sri_sim_bayes[upper.tri(sri_sim_bayes)], xlab="SRI", ylab="Ising Bayes SRI")
abline(a=0, b=1)

mean(abs(sri[upper.tri(sri)] - sri_sim_bayes[upper.tri(sri_sim_bayes)]))
plot(sri[upper.tri(sri)], isri[upper.tri(isri)])

isri <- apply(chain$beta, c(2, 3), function(x) quantile(x, probs=c(0.025, 0.5, 0.975)))
df <- data.frame(lower=isri[1, , ][upper.tri(sri)], middle=isri[2, , ][upper.tri(sri)], upper=isri[3, , ][upper.tri(sri)], sri=sri[upper.tri(sri)])
ggplot(df, aes(x=sri, y=middle)) +
  geom_point() +
  geom_errorbar(aes(ymin=lower, ymax=upper)) +
  labs(x="SRI", y="Ising Interaction Term")
```

```{r}
# Convert fitted parameters to plug in to Ising model.
chain <- extract(fit_bayes)
params <- list(
  alpha=chain$alpha,
  beta=array(0, dim=c(nrow(chain$beta), N, N))
)
for (i in 1:N) {
  params$beta[, i, -i] <- chain$beta[, i, ]
}
# Take mean parameter estimate of beta[i, j] and beta[j, i]. Is this a good idea? Could upper.tri it but tricky over array.
params$beta <- 0.5 * (aperm(params$beta, c(1, 3, 2)) + params$beta)

X_sim_bayes <- sample_data_from_ising_bayes(params, thin=G, cpp=TRUE)

# Calculate SRI from original and simulated data.
sri <- asnipe::get_network(X)
sri_sim_bayes <- asnipe::get_network(X_sim_bayes)

# Plot SRI from original data against the SRI from simulated data.
plot(sri[upper.tri(sri)], sri_sim_bayes[upper.tri(sri_sim_bayes)], xlab="SRI", ylab="Ising Bayes SRI")
abline(a=0, b=1)

plot(sri[upper.tri(sri)], apply(params$beta, c(2, 3), mean)[upper.tri(sri)], xlab="SRI", ylab="Ising Bayes Interaction Term")
```

```{r}
sri_boots <- array(0, dim=c(1000, N, N))
for (iter in 1:1000) {
  sri_boots[iter, , ] <- asnipe::get_network(X[sample(1:G, G, replace=TRUE), ])
}

sri_boots_q <- apply(sri_boots, c(2, 3), function(x) quantile(x, probs=c(0.025, 0.5, 0.975)))

df <- data.frame(lower=sri_boots_q[1, , ][upper.tri(sri)], middle=sri_boots_q[2, , ][upper.tri(sri)], upper=sri_boots_q[3, , ][upper.tri(sri)], sri=sri[upper.tri(sri)])

ggplot(df, aes(x=sri, y=middle)) +
  geom_point() +
  geom_errorbar(aes(ymin=lower, ymax=upper)) +
  labs(x="SRI", y="Bootstrap SRI")
```
